# Copyright 1996-2024 Cyberbotics Ltd.
# Licensed under the Apache License, Version 2.0
import asyncio
import math
from controller import Robot
from asyncua import Server, ua
import threading, time
from datetime import datetime
from flask import Flask
import cv2
import numpy as np
from pupil_apriltags import Detector
import redis
import json

# ==== Redis Client ====
redis_client = redis.Redis(host="192.168.0.71", port=26379, db=0, decode_responses=True)
REDIS_APRILTAG_CHANNEL = "apriltag_detection"
REDIS_APRILTAG_KEY = "apriltag_latest"

# ==== Imports v√† kh·ªüi t·∫°o apriltag dectector ====

# Kh·ªüi t·∫°o detector (n√™n t·∫°o 1 l·∫ßn, kh√¥ng t·∫°o l·∫°i m·ªói frame)
_apriltag_detector = Detector(
    families="tag36h11",
    nthreads=4,
    quad_decimate=1.0,
    quad_sigma=0.0,
    refine_edges=True,
    decode_sharpening=0.25,
    debug=False
)


# Camera intrinsic parameters
# fieldOfView trong robot = 2.05949 radian = 117.99 ƒë·ªô
# Camera resolution: 1280 x 720
CAMERA_FOV_RAD = 2.05949
CAMERA_WIDTH = 1280
CAMERA_HEIGHT = 720

# T√≠nh focal length (pixels) t·ª´ FOV
# focal_length = (width / 2) / tan(fov / 2)
CAMERA_FOCAL_LENGTH = (CAMERA_WIDTH / 2.0) / np.tan(CAMERA_FOV_RAD / 2.0)

# K√≠ch th∆∞·ªõc th·ª±c c·ªßa AprilTag (cm) - ƒëi·ªÅu ch·ªânh theo tag th·ª±c t·∫ø
APRILTAG_SIZE_CM = 16.0  # K√≠ch th∆∞·ªõc c·∫°nh c·ªßa AprilTag (cm)

def analyze_apriltag_offset(image, depth_image=None):
    """
    Ph√¢n t√≠ch v·ªã tr√≠ AprilTag v√† tr·∫£ v·ªÅ kho·∫£ng c√°ch l·ªách tr√°i/ph·∫£i th·ª±c t·∫ø (cm) v√† chi·ªÅu s√¢u

    Parameters
    ----------
    image : np.ndarray
        ·∫¢nh ƒë·∫ßu v√†o (BGR ho·∫∑c grayscale)
    depth_image : np.ndarray | None
        ·∫¢nh depth t·ª´ depth_camera (float32, ƒë∆°n v·ªã m√©t)
        N·∫øu None, s·∫Ω ∆∞·ªõc l∆∞·ª£ng kho·∫£ng c√°ch t·ª´ k√≠ch th∆∞·ªõc tag

    Returns
    -------
    lateral_offset_cm : float | None
        Kho·∫£ng c√°ch l·ªách tr√°i/ph·∫£i so v·ªõi t√¢m camera (cm)
        (+) AprilTag ·ªü b√™n ph·∫£i t√¢m camera -> robot c·∫ßn di chuy·ªÉn sang ph·∫£i
        (-) AprilTag ·ªü b√™n tr√°i t√¢m camera -> robot c·∫ßn di chuy·ªÉn sang tr√°i
        Gi√° tr·ªã n√†y KH√îNG THAY ƒê·ªîI khi robot di chuy·ªÉn t·ªãnh ti·∫øn (n·∫øu kh√¥ng l·ªách g√≥c)

    yaw_deg : float | None
        G√≥c xoay c·ªßa AprilTag so v·ªõi camera (ƒë·ªô)
        0¬∞ = AprilTag vu√¥ng g√≥c v·ªõi camera
        (+) xoay ng∆∞·ª£c chi·ªÅu kim ƒë·ªìng h·ªì

    distance_cm : float | None
        Kho·∫£ng c√°ch (chi·ªÅu s√¢u) t·ª´ camera ƒë·∫øn AprilTag (cm)
        ƒê·ªçc t·ª´ depth_camera n·∫øu c√≥, n·∫øu kh√¥ng s·∫Ω ∆∞·ªõc l∆∞·ª£ng t·ª´ k√≠ch th∆∞·ªõc tag
    """

    # ---- 1. Chuy·ªÉn sang grayscale n·∫øu c·∫ßn ----
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image

    h, w = gray.shape

    # ---- 2. Detect AprilTag ----
    detections = _apriltag_detector.detect(gray)

    if len(detections) == 0:
        return None, None, None

    # ---- 3. L·∫•y tag ƒë·∫ßu ti√™n (ho·∫∑c ch·ªçn theo ID n·∫øu c·∫ßn) ----
    tag = detections[0]
    corners = tag.corners
    cx, cy = tag.center

    # ---- 4. T√≠nh kho·∫£ng c√°ch (chi·ªÅu s√¢u) t·ª´ depth_camera ----
    distance_cm = None

    if depth_image is not None:
        # L·∫•y depth t·∫°i t√¢m c·ªßa AprilTag
        cx_int, cy_int = int(cx), int(cy)

        # ƒê·∫£m b·∫£o t·ªça ƒë·ªô n·∫±m trong ph·∫°m vi ·∫£nh
        cx_int = max(0, min(cx_int, depth_image.shape[1] - 1))
        cy_int = max(0, min(cy_int, depth_image.shape[0] - 1))

        # L·∫•y depth value (m√©t) v√† chuy·ªÉn sang cm
        # L·∫•y trung b√¨nh v√πng 5x5 pixels xung quanh t√¢m ƒë·ªÉ gi·∫£m nhi·ªÖu
        half_size = 2
        y_start = max(0, cy_int - half_size)
        y_end = min(depth_image.shape[0], cy_int + half_size + 1)
        x_start = max(0, cx_int - half_size)
        x_end = min(depth_image.shape[1], cx_int + half_size + 1)

        depth_region = depth_image[y_start:y_end, x_start:x_end]

        # L·ªçc b·ªè c√°c gi√° tr·ªã v√¥ c·ª±c ho·∫∑c NaN
        valid_depths = depth_region[(depth_region > 0) & (np.isfinite(depth_region))]

        if len(valid_depths) > 0:
            depth_m = np.median(valid_depths)  # D√πng median ƒë·ªÉ robust h∆°n
            distance_cm = depth_m * 100.0  # Chuy·ªÉn t·ª´ m√©t sang cm

    # ---- 5. N·∫øu kh√¥ng c√≥ depth_image, ∆∞·ªõc l∆∞·ª£ng t·ª´ k√≠ch th∆∞·ªõc tag ----
    if distance_cm is None:
        # L·∫•y k√≠ch th∆∞·ªõc trung b√¨nh c·ªßa 4 c·∫°nh
        side1 = np.linalg.norm(corners[1] - corners[0])
        side2 = np.linalg.norm(corners[2] - corners[1])
        side3 = np.linalg.norm(corners[3] - corners[2])
        side4 = np.linalg.norm(corners[0] - corners[3])
        tag_size_px = (side1 + side2 + side3 + side4) / 4.0

        # C√¥ng th·ª©c: distance = (real_size * focal_length) / pixel_size
        distance_cm = (APRILTAG_SIZE_CM * CAMERA_FOCAL_LENGTH) / tag_size_px

    # ---- 6. T√≠nh offset pixel so v·ªõi t√¢m ·∫£nh ----
    offset_px = cx - (w / 2.0)

    # ---- 7. Chuy·ªÉn offset t·ª´ pixel sang cm ----
    # S·ª≠ d·ª•ng similar triangles: offset_cm / distance_cm = offset_px / focal_length
    lateral_offset_cm = (offset_px * distance_cm) / CAMERA_FOCAL_LENGTH

    # ---- 8. L·ªách g√≥c (yaw) c·ªßa AprilTag ----
    # vector c·∫°nh tr√™n c·ªßa tag: corner 0 -> corner 1
    v = corners[1] - corners[0]
    yaw_rad = np.arctan2(v[1], v[0])
    yaw_deg = np.degrees(yaw_rad)

    return lateral_offset_cm, yaw_deg, distance_cm

# ===== Constants (gi·ªØ nguy√™n nh∆∞ C) =====

TURN_WHEEL_SPEED=-0.3
FORWARD_FAST_SPEED = 3
FORWARD_NORMAL_SPEED = 4.0
FORWARD_SLOW_SPEED = 10
BACKWARD_SPEED = 4.0
TURN_SPEED = 0.5

# ===== Robot init =====
robot = Robot()
time_step = int(robot.getBasicTimeStep())

# ===== Motors =====
motor_back_left_joint = robot.getDevice("back_left_wheel_joint")
motor_back_right_joint = robot.getDevice("back_right_wheel_joint")
motor_front_joint = robot.getDevice("front_wheel_joint")

motor_back_left_joint.setPosition(float("inf"))
motor_back_right_joint.setPosition(float("inf"))
motor_front_joint.setPosition(float("inf"))

motor_back_left_joint.setVelocity(0.0)
motor_back_right_joint.setVelocity(0.0)
motor_front_joint.setVelocity(0.0)

motor_back_left = robot.getDevice("back_left_wheel")
motor_back_right = robot.getDevice("back_right_wheel")
motor_front = robot.getDevice("front_wheel")

motor_back_left.setPosition(float("inf"))
motor_back_right.setPosition(float("inf"))
motor_front.setPosition(float("inf"))

motor_back_left.setVelocity(0.0)
motor_back_right.setVelocity(0.0)
motor_front.setVelocity(0.0)

# ===== Sensors =====
depth_camera = robot.getDevice("depth_camera")
depth_camera.enable(time_step)

camera = robot.getDevice("camera")
camera.enable(time_step)

gps = robot.getDevice("gps")
gps.enable(time_step)

imu = robot.getDevice("inertial unit")
imu.enable(time_step)

robot_front_wheel_radian_sensor = robot.getDevice("front_caster_joint_sensor")
robot_front_wheel_radian_sensor.enable(time_step)

robot_back_left_wheel_radian_sensor = robot.getDevice("back_left_caster_joint_sensor")
robot_back_left_wheel_radian_sensor.enable(time_step)

robot_back_right_wheel_radian_sensor = robot.getDevice("back_right_caster_joint_sensor")
robot_back_right_wheel_radian_sensor.enable(time_step)

# ===== Task Queue cho Main Loop =====
# Thay th·∫ø time.sleep b·∫±ng h·ªá th·ªëng task-based
class MonitorTask:
    """Base class cho c√°c monitoring task"""
    def __init__(self):
        self.completed = False
        self.callback = None

    def check_and_execute(self):
        """Ki·ªÉm tra ƒëi·ªÅu ki·ªán v√† th·ª±c thi - g·ªçi trong main loop"""
        raise NotImplementedError

    def is_completed(self):
        return self.completed

class MonitorWheelAngleTask(MonitorTask):
    """Task ƒë·ªÉ monitor g√≥c b√°nh xe"""
    def __init__(self, target_radian, callback=None):
        super().__init__()
        self.target_radian = target_radian
        self.callback = callback

    def check_and_execute(self):
        current_angle = get_current_robot_front_wheel_in_radiant()
        # print(f"Current front wheel angle: {current_angle} with target {self.target_radian}")

        if abs(current_angle - self.target_radian) <= 0.006:
            # ƒê·∫°t m·ª•c ti√™u - d·ª´ng motor
            motor_front_joint.setVelocity(0)
            motor_back_left_joint.setVelocity(0)
            motor_back_right_joint.setVelocity(0)
            self.completed = True
            if self.callback is not None:
                self.callback()
            return True
        return False

class MonitorBodyHeadingTask(MonitorTask):
    """Task ƒë·ªÉ monitor heading c·ªßa robot"""
    def __init__(self, initial_heading, target_radian, callback=None):
        super().__init__()
        self.initial_heading = initial_heading
        self.target_radian = target_radian
        self.callback = callback

    def check_and_execute(self):
        current_heading = get_current_robot_heading()
        print("Initial heading:", self.initial_heading)
        print("Current heading :", current_heading)
        heading_diff = abs(abs(current_heading) - abs(self.initial_heading))
        print(f"Waiting to reach target heading...: {heading_diff} vs {self.target_radian}")

        if abs(heading_diff - self.target_radian) <= 0.006:
            print(f"Target heading reached: {heading_diff} with target {self.target_radian}")
            set_velocity(0, 0, 0)
            self.completed = True
            # Quay b√°nh xe v·ªÅ v·ªã tr√≠ ban ƒë·∫ßu
            add_turn_all_wheels_task(0, -1, self.callback)
            return True
        return False

# Danh s√°ch c√°c task ƒëang ch·∫°y
active_tasks = []
task_lock = threading.Lock()

def add_task(task):
    """Th√™m task v√†o queue - thread-safe"""
    with task_lock:
        active_tasks.append(task)

def process_tasks():
    """X·ª≠ l√Ω t·∫•t c·∫£ c√°c task trong main loop"""
    with task_lock:
        # L·ªçc b·ªè c√°c task ƒë√£ ho√†n th√†nh
        tasks_to_process = active_tasks.copy()

    completed_tasks = []
    for task in tasks_to_process:
        if task.check_and_execute():
            completed_tasks.append(task)

    # X√≥a c√°c task ƒë√£ ho√†n th√†nh
    with task_lock:
        for task in completed_tasks:
            if task in active_tasks:
                active_tasks.remove(task)

# ==== H√†m set t·ªëc ƒë·ªô ====
def set_velocity(left_speed, right_speed, front_seed):
    motor_back_left.setVelocity(left_speed)
    motor_back_right.setVelocity(right_speed)
    motor_front.setVelocity(front_seed)

def add_turn_all_wheels_task(turn_radian, turn_direction = 1, callback=None):
    """Th√™m task ƒë·ªÉ quay t·∫•t c·∫£ b√°nh xe"""
    print(f"Turning all wheels... {turn_radian}")
    speed = (TURN_WHEEL_SPEED / 2 * 1.5 ) * turn_direction

    motor_front_joint.setVelocity(speed)
    motor_back_left_joint.setVelocity(speed)
    motor_back_right_joint.setVelocity(speed)

    # Th√™m task ƒë·ªÉ monitor
    task = MonitorWheelAngleTask(turn_radian, callback)
    add_task(task)

def turn_body(turn_radian):
    def start_turn_body():
        set_velocity(-FORWARD_SLOW_SPEED/10, -FORWARD_SLOW_SPEED/10, FORWARD_SLOW_SPEED/5)
        current_heading = get_current_robot_heading()
        print(f"Current heading: {current_heading}")
        print(f"Target heading: {turn_radian}")

        # Th√™m task ƒë·ªÉ monitor body heading
        task = MonitorBodyHeadingTask(current_heading, turn_radian, None)
        add_task(task)

    add_turn_all_wheels_task(turn_radian, 1,  start_turn_body)


# ====== H√†m ƒë·ªçc sensors ======

# Cache cho GPS v√† IMU data
last_gps_update = 0
last_imu_update = 0
cached_gps_data = (0, 0)
cached_heading = 0
GPS_UPDATE_INTERVAL = 0.1
IMU_UPDATE_INTERVAL = 0.05

def get_current_robot_pose():
    global last_gps_update, cached_gps_data
    current_time = time.time()

    if current_time - last_gps_update > GPS_UPDATE_INTERVAL:
        gps_values = gps.getValues()
        cached_gps_data = (gps_values[0], gps_values[1])
        last_gps_update = current_time

    return cached_gps_data

def get_current_robot_heading():
    global last_imu_update, cached_heading
    current_time = time.time()

    if current_time - last_imu_update > IMU_UPDATE_INTERVAL:
        rpy = imu.getRollPitchYaw()
        yaw = rpy[2]
        yaw = round(yaw, 6) + 1.570798
        cached_heading = math.atan2(math.sin(yaw), math.cos(yaw))
        last_imu_update = current_time

    return cached_heading

def get_current_robot_front_wheel_in_radiant():
    value = robot_front_wheel_radian_sensor.getValue()
    value  = (round((value - math.pi) % (2 * math.pi) - math.pi, 2)) * -1
    # print(f"Getting front wheel radian: {value}")
    return value

def get_current_robot_back_left_wheel_in_radiant():
    value = robot_back_left_wheel_radian_sensor.getValue()
    value  = (round((value  - math.pi) % (2 * math.pi) - math.pi, 2)) * -1
    # print(f"Getting back left wheel radian: {value}")
    return value

def get_current_robot_back_right_wheel_in_radiant():
    value = robot_back_right_wheel_radian_sensor.getValue()
    value  = (round((value  - math.pi) % (2 * math.pi) - math.pi, 2)) * -1
    # print(f"Getting back right wheel radian: {value}")
    return value

# ==== OPC UA Server ====
class RobotCommandServer:
    def __init__(self, endpoint="opc.tcp://0.0.0.0:4840/freeopcua/server/"):
        self.sub = None
        self.server = Server()
        self.endpoint = endpoint
        self.forward_var = None
        self.namespace_idx = None
        self.all_wheel_speed_var = None
        self.all_wheel_turn_var = None
        self.turn_front_var = None
        self.is_monitoring = False
        self.monitor_thread = None
        self.last_processed_command = None  # ƒê·ªÉ tr√°nh x·ª≠ l√Ω command tr√πng l·∫∑p

    async def setup_server(self):
        """Initialize server configuration"""
        await self.server.init()
        self.server.set_endpoint(self.endpoint)
        self.server.set_security_policy([ua.SecurityPolicyType.NoSecurity])

        uri = "http://example.org"
        self.namespace_idx = await self.server.register_namespace(uri)

        objects = self.server.get_objects_node()
        robot_device = await objects.add_object(self.namespace_idx, "RobotController")

        # Bi·∫øn t·ªëc ƒë·ªô ƒëi th·∫≥ng
        self.all_wheel_speed_var = await robot_device.add_variable(
            self.namespace_idx,
            "AllWheelSpeed",
            ua.Variant(0.0, ua.VariantType.Float)
        )
        await self.all_wheel_speed_var.set_writable(True)

        # Bi·∫øn ƒëi·ªÅu khi·ªÉn quay 3 b√°nh
        self.all_wheel_turn_var = await robot_device.add_variable(
            self.namespace_idx,
            "AllWheelTurn",
            ua.Variant(0.0, ua.VariantType.Float)
        )
        await self.all_wheel_turn_var.set_writable(True)
        print(f"AllWheelSpeed NodeId: NamespaceId { self.all_wheel_speed_var.nodeid.NamespaceIndex}, NodeId {self.all_wheel_speed_var.nodeid.Identifier}", )

    async def setup_internal_subscription(self):
        class Handler:
            @staticmethod
            def datachange_notification(node, val, data):
                print("üö® VALUE CHANGED")
                print("NodeId:", node.nodeid)
                print("Value:", val)
                if node.nodeid.Identifier == self.all_wheel_speed_var.nodeid.Identifier:
                    set_velocity(val, val, val)
                elif node.nodeid.Identifier == self.all_wheel_turn_var.nodeid.Identifier:
                    if val is not None and val != 0.0:
                        radiant = val / 180 * math.pi
                        turn_body(radiant)

        handler = Handler()
        self.sub = await self.server.create_subscription(0, handler)

        await self.sub.subscribe_data_change(self.all_wheel_speed_var)
        await self.sub.subscribe_data_change(self.all_wheel_turn_var)

    async def run(self):
        await self.setup_server()
        await self.setup_internal_subscription()

        print("ü§ñ OPC UA Robot Server running...")
        async with self.server:
            while True:
                await asyncio.sleep(100)


# ==== API Server ====
app = Flask(__name__)
@app.route("/current-robot", methods=["GET"])
def get_current_robot():
    try:
        x, y = get_current_robot_pose()
        heading = get_current_robot_heading()

        current_robot = {
            "timestamp": time.time_ns(),
            "camera_id": 0,
            "object_id": 0,
            "yaw": heading,
            "center": [x, y],
            "corners": [],
        }
        return {"status": "ok", "robot": current_robot}
    except Exception as e:
        print(f"Redis publish error: {e}")


def run_flask():
    print("üåê Starting Flask server on http://0.0.0.0:6000")
    app.run(host="0.0.0.0", port=6000, debug=False, use_reloader=False, threaded=True)


# ==== Kh·ªüi t·∫°o servers ====
print("ü§ñ Starting Robot Controller...")

# Flask
flask_thread = threading.Thread(target=run_flask, daemon=True)
flask_thread.start()

# OPC UA
server = RobotCommandServer()
opcua_thread = threading.Thread(
    target=lambda: asyncio.run(server.run()),
    daemon=True
)
opcua_thread.start()

print("üîÑ Starting Webots simulation loop...")

# L·∫•y k√≠ch th∆∞·ªõc camera
camera_width = camera.getWidth()
camera_height = camera.getHeight()
depth_camera_width = depth_camera.getWidth()
depth_camera_height = depth_camera.getHeight()

# Counter ƒë·ªÉ gi·∫£m t·∫ßn su·∫•t x·ª≠ l√Ω apriltag (kh√¥ng c·∫ßn m·ªói frame)
apriltag_check_counter = 0
APRILTAG_CHECK_INTERVAL = 10  # Ki·ªÉm tra m·ªói 10 timesteps

# üî• Main loop - X·ª≠ l√Ω t·∫•t c·∫£ tasks v·ªõi robot.step thay v√¨ time.sleep
while robot.step(time_step) != -1:
    # X·ª≠ l√Ω c√°c monitoring tasks trong m·ªói timestep
    process_tasks()

    # X·ª≠ l√Ω AprilTag detection t·ª´ camera
    apriltag_check_counter += 1
    if apriltag_check_counter >= APRILTAG_CHECK_INTERVAL:
        apriltag_check_counter = 0

        # L·∫•y ·∫£nh t·ª´ camera
        camera_data = camera.getImage()

        # L·∫•y depth image t·ª´ depth_camera
        depth_data = depth_camera.getRangeImage()
        depth_image = None
        if depth_data:
            # Chuy·ªÉn ƒë·ªïi depth data sang numpy array (float32, ƒë∆°n v·ªã m√©t)
            depth_image = np.array(depth_data, dtype=np.float32).reshape((depth_camera_height, depth_camera_width))

        if camera_data:
            # Chuy·ªÉn ƒë·ªïi t·ª´ raw bytes sang numpy array (BGRA format)
            image = np.frombuffer(camera_data, np.uint8).reshape((camera_height, camera_width, 4))
            # Chuy·ªÉn t·ª´ BGRA sang BGR
            image_bgr = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)

            # Ph√¢n t√≠ch AprilTag v·ªõi depth image
            lateral_offset_cm, yaw_deg, distance_cm = analyze_apriltag_offset(image_bgr, depth_image)

            if lateral_offset_cm is not None:
                print(f"üìç AprilTag detected: lateral_offset={lateral_offset_cm:.2f}cm, yaw={yaw_deg:.2f}¬∞, distance={distance_cm:.2f}cm")

                # Publish k·∫øt qu·∫£ v√†o Redis
                try:
                    apriltag_data = {
                        "timestamp": time.time_ns(),
                        "lateral_offset_cm": round(lateral_offset_cm, 2),
                        "yaw_deg": round(yaw_deg, 2),
                        "distance_cm": round(distance_cm, 2),
                        "detected": True
                    }
                    apriltag_json = json.dumps(apriltag_data)

                    # L∆∞u v√†o key ƒë·ªÉ c√≥ th·ªÉ ƒë·ªçc b·∫•t c·ª© l√∫c n√†o
                    redis_client.set(REDIS_APRILTAG_KEY, apriltag_json)

                    # Publish v√†o channel ƒë·ªÉ c√°c subscriber nh·∫≠n ƒë∆∞·ª£c realtime
                    redis_client.publish(REDIS_APRILTAG_CHANNEL, apriltag_json)
                except Exception as e:
                    print(f"‚ùå Redis publish error: {e}")
